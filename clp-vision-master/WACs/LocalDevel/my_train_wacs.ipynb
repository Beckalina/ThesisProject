{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import json\n",
    "import h5py as h5\n",
    "from collections import Counter, defaultdict\n",
    "import configparser\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "my_config = '../../Config/default.cfg'\n",
    "with open(my_config, 'r', encoding='utf-8') as f:\n",
    "    config.read_file(f)\n",
    "\n",
    "corpora_base = config.get('DEFAULT', 'corpora_base')\n",
    "dsgv_home = config.get('DSGV-PATHS', 'dsgv_home')\n",
    "\n",
    "preproc_path = dsgv_home + '/Preproc/PreprocOut/'\n",
    "feats_path = dsgv_home + '/ExtractFeats/ExtractOut/'\n",
    "\n",
    "# The first features in the image feature Xs encode the region ID\n",
    "ID_FEATS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99527, 2058)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5.File(feats_path + 'saiapr_bbdf_rsn50-max.hdf5') as f:\n",
    "    n1 = np.array(f[\"img_feats\"])\n",
    "\n",
    "n1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(preproc_path + 'saiapr_90-10_splits.json', 'r') as f:\n",
    "    s_splits = json.load(f)\n",
    "    \n",
    "# X = np.load(feats_path + 'mscoco_vgg19-fc2.npz')['arr_0']\n",
    "with h5.File(feats_path + 'saiapr_bbdf_rsn50-max.hdf5') as f:\n",
    "    X = np.array(f[\"img_feats\"])\n",
    "\n",
    "saiapr_refdf = pd.read_json(preproc_path + 'saiapr_refdf.json.gz',\n",
    "                         typ='frame', orient='split', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_X_by_filelist(X, filelist):\n",
    "    if type(X) == np.ndarray:\n",
    "        tmp_df = pd.DataFrame(X)\n",
    "        return np.array(tmp_df[tmp_df.iloc[:, 1].isin(filelist)])\n",
    "    else:  # assume that X is a dask array\n",
    "        image_id_list = X[:, 1].compute()\n",
    "        train_mask = np.isin(image_id_list, filelist)\n",
    "        return X[train_mask]\n",
    "\n",
    "def filter_refdf_by_filelist(refdf, filelist):\n",
    "    return pd.merge(refdf, pd.DataFrame(filelist, columns=['image_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_corpus</th>\n",
       "      <th>image_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>r_corpus</th>\n",
       "      <th>rex_id</th>\n",
       "      <th>refexp</th>\n",
       "      <th>tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8756</td>\n",
       "      <td>2</td>\n",
       "      <td>referit</td>\n",
       "      <td>0</td>\n",
       "      <td>sunray at very top</td>\n",
       "      <td>[[sunray, NN], [at, IN], [very, RB], [top, JJ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8756</td>\n",
       "      <td>10</td>\n",
       "      <td>referit</td>\n",
       "      <td>1515</td>\n",
       "      <td>guy in the middle in front</td>\n",
       "      <td>[[guy, NN], [in, IN], [the, DT], [middle, NN],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8756</td>\n",
       "      <td>9</td>\n",
       "      <td>referit</td>\n",
       "      <td>2252</td>\n",
       "      <td>upper right corner</td>\n",
       "      <td>[[upper, JJ], [right, NN], [corner, NN]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8756</td>\n",
       "      <td>6</td>\n",
       "      <td>referit</td>\n",
       "      <td>5631</td>\n",
       "      <td>any of the four people on left</td>\n",
       "      <td>[[any, DT], [of, IN], [the, DT], [four, CD], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8756</td>\n",
       "      <td>1</td>\n",
       "      <td>referit</td>\n",
       "      <td>10052</td>\n",
       "      <td>sky top left</td>\n",
       "      <td>[[sky, NN], [top, NN], [left, VBD]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108066</th>\n",
       "      <td>0</td>\n",
       "      <td>24719</td>\n",
       "      <td>1</td>\n",
       "      <td>referit</td>\n",
       "      <td>119562</td>\n",
       "      <td>head</td>\n",
       "      <td>[[head, NN]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108067</th>\n",
       "      <td>0</td>\n",
       "      <td>31705</td>\n",
       "      <td>1</td>\n",
       "      <td>referit</td>\n",
       "      <td>119566</td>\n",
       "      <td>jersey</td>\n",
       "      <td>[[jersey, NN]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108068</th>\n",
       "      <td>0</td>\n",
       "      <td>40528</td>\n",
       "      <td>1</td>\n",
       "      <td>referit</td>\n",
       "      <td>119624</td>\n",
       "      <td>right middle</td>\n",
       "      <td>[[right, RB], [middle, NN]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108069</th>\n",
       "      <td>0</td>\n",
       "      <td>30772</td>\n",
       "      <td>1</td>\n",
       "      <td>referit</td>\n",
       "      <td>120023</td>\n",
       "      <td>tall tree</td>\n",
       "      <td>[[tall, DT], [tree, NN]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108070</th>\n",
       "      <td>0</td>\n",
       "      <td>32072</td>\n",
       "      <td>1</td>\n",
       "      <td>referit</td>\n",
       "      <td>120068</td>\n",
       "      <td>court</td>\n",
       "      <td>[[court, NN]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108071 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        i_corpus  image_id  region_id r_corpus  rex_id  \\\n",
       "0              0      8756          2  referit       0   \n",
       "1              0      8756         10  referit    1515   \n",
       "2              0      8756          9  referit    2252   \n",
       "3              0      8756          6  referit    5631   \n",
       "4              0      8756          1  referit   10052   \n",
       "...          ...       ...        ...      ...     ...   \n",
       "108066         0     24719          1  referit  119562   \n",
       "108067         0     31705          1  referit  119566   \n",
       "108068         0     40528          1  referit  119624   \n",
       "108069         0     30772          1  referit  120023   \n",
       "108070         0     32072          1  referit  120068   \n",
       "\n",
       "                                refexp  \\\n",
       "0                   sunray at very top   \n",
       "1           guy in the middle in front   \n",
       "2                   upper right corner   \n",
       "3       any of the four people on left   \n",
       "4                         sky top left   \n",
       "...                                ...   \n",
       "108066                            head   \n",
       "108067                          jersey   \n",
       "108068                    right middle   \n",
       "108069                       tall tree   \n",
       "108070                           court   \n",
       "\n",
       "                                                   tagged  \n",
       "0         [[sunray, NN], [at, IN], [very, RB], [top, JJ]]  \n",
       "1       [[guy, NN], [in, IN], [the, DT], [middle, NN],...  \n",
       "2                [[upper, JJ], [right, NN], [corner, NN]]  \n",
       "3       [[any, DT], [of, IN], [the, DT], [four, CD], [...  \n",
       "4                     [[sky, NN], [top, NN], [left, VBD]]  \n",
       "...                                                   ...  \n",
       "108066                                       [[head, NN]]  \n",
       "108067                                     [[jersey, NN]]  \n",
       "108068                        [[right, RB], [middle, NN]]  \n",
       "108069                           [[tall, DT], [tree, NN]]  \n",
       "108070                                      [[court, NN]]  \n",
       "\n",
       "[108071 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = filter_X_by_filelist(X, s_splits['train'])\n",
    "refdf_train = filter_refdf_by_filelist(saiapr_refdf, s_splits['train'])\n",
    "refdf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2den(refdf, refcol='refexp', regcol='region_id'):\n",
    "    '''Given refdf, returns dict of occurences (id triples) of words from expressions.'''\n",
    "    word2den = defaultdict(list)\n",
    "    for _, row in refdf.iterrows():\n",
    "        exprlist = row[refcol].split()\n",
    "        # TODO: Could take filter function that filters out some occurences.\n",
    "        #   E.g., tagger that tags whole expression & returns only the nouns.\n",
    "        for word in exprlist:\n",
    "            word_den_list = word2den[word].append((row['i_corpus'],\n",
    "                                                   row['image_id'],\n",
    "                                                   row[regcol]))\n",
    "    return {k: list(set(v)) for k,v in word2den.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.12 s, sys: 43.9 ms, total: 7.16 s\n",
      "Wall time: 7.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2den = create_word2den(refdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 40630, 1), (0, 40628, 3), (0, 40630, 3), (0, 40628, 1), (0, 40630, 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2den is an index of vocab to list of occurrences (i_corpus, image_id, region_id)\n",
    "word2den['gorilla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_id_index(X, id_feats=ID_FEATS):\n",
    "    return dict(zip([tuple(e) for e in X[:,:id_feats].astype(int).tolist()], range(len(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.5 ms, sys: 291 ms, total: 365 ms\n",
      "Wall time: 480 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_idx = make_X_id_index(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89536"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask_matrix(X, X_idx, word2den, wordlist):\n",
    "    mask_matrix = []\n",
    "    for this_word in wordlist:\n",
    "        this_word_vec = np.zeros(len(X))\n",
    "        if this_word in word2den:\n",
    "            this_word_vec[[X_idx[i] for i in word2den[this_word] if i in X_idx]] = 1\n",
    "        mask_matrix.append(this_word_vec)\n",
    "    mask_matrix = np.array(mask_matrix, dtype=bool)\n",
    "    return mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 2.64 s, total: 4.22 s\n",
      "Wall time: 6.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mask_matrix = make_mask_matrix(X_t, X_idx, word2den, word2den.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## N.B.: Replace with make_X_for_word from below! Can be used for extracting\n",
    "##   test data as well..\n",
    "\n",
    "def make_train_for_word(X, word2den, mask_matrix, word, neg_max=20000):\n",
    "    if word not in word2den:\n",
    "        #raise ValueError(\"No mask available for this word! (%s)\" % (word))\n",
    "        print(\"Error!! No mask available for this word! (%s)\" % (word))\n",
    "        return None\n",
    "    this_mask = mask_matrix[list(word2den.keys()).index(word)]\n",
    "    #this_mask = mask_matrix[list(word2den)[word]]\n",
    "    X_pos = X[this_mask, ID_FEATS:]\n",
    "    y_pos = np.ones(len(X_pos), dtype=int)\n",
    "    \n",
    "    neg_indx = np.arange(mask_matrix.shape[1])[~this_mask]\n",
    "    np.random.shuffle(neg_indx)\n",
    "    X_neg = X[neg_indx[:neg_max], ID_FEATS:]\n",
    "    y_neg = np.zeros(len(X_neg), dtype=int)\n",
    "\n",
    "    X_out = np.concatenate([X_pos, X_neg], axis=0)\n",
    "    y_out = np.concatenate([y_pos, y_neg])\n",
    "    return shuffle(X_out, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -T prof1 -f make_train_for_word X_this_w, y_this_w = make_train_for_word(X_t, word2den, mask_matrix, 'cow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sped up `make_train_for_word` by limiting the size of the negative set. Was 40secs, now 3 secs. Still slower than I would like. But selecting a very large portion of the matrix with a boolean vector seems to be very slow. Maybe there is a more clever way to do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 141 ms, sys: 429 ms, total: 571 ms\n",
      "Wall time: 580 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_this_w, y_this_w = make_train_for_word(X_t, word2den, mask_matrix, 'cow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9497, 89545)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the set of words for which WAC is trained, by frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 40\n",
    "\n",
    "counts = mask_matrix.sum(axis=1)\n",
    "\n",
    "wordlist = np.array(list(word2den.keys()))[counts > min_freq]\n",
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.12000000e+02, 1.00000000e+00, ...,\n",
       "        6.61273148e-01, 1.33333333e+00, 1.07406290e-01],\n",
       "       [0.00000000e+00, 1.12000000e+02, 2.00000000e+00, ...,\n",
       "        4.94444444e-02, 1.33333333e+00, 7.78918410e-01],\n",
       "       [0.00000000e+00, 1.12000000e+02, 3.00000000e+00, ...,\n",
       "        7.77719907e-02, 1.33333333e+00, 7.31304010e-01],\n",
       "       ...,\n",
       "       [0.00000000e+00, 4.06880000e+04, 1.00000000e+00, ...,\n",
       "        5.06938657e-01, 1.33333333e+00, 1.13749237e-01],\n",
       "       [0.00000000e+00, 4.06890000e+04, 1.00000000e+00, ...,\n",
       "        1.53125000e-01, 1.33333333e+00, 2.45837571e-01],\n",
       "       [0.00000000e+00, 4.06890000e+04, 2.00000000e+00, ...,\n",
       "        2.12245370e-01, 1.33333333e+00, 5.66580876e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaling = False\n",
    "if scaling:\n",
    "    from sklearn import preprocessing\n",
    "    scaler = preprocessing.StandardScaler().fit(X_t)\n",
    "    X_scaled = scaler.transform(X_t)\n",
    "    X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_this_word(X, word2den, mask_matrix, this_word):\n",
    "    X_this_w, y_this_w = make_train_for_word(X_t, word2den, mask_matrix, this_word)\n",
    "    print(this_word, X_this_w.shape[0])\n",
    "    classifier = linear_model.LogisticRegression(penalty='l2', warm_start=True, max_iter=400)\n",
    "    this_wac = classifier.fit(X_this_w, y_this_w)\n",
    "    return (this_word, y_this_w.sum(), len(X_this_w), this_wac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wacs = [train_this_word(X, word2den, mask_matrix, this_word)\\\n",
    "        for this_word in wordlist[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wacs = Parallel(n_jobs=2, require='sharedmem', prefer='threads')\\\n",
    "               (delayed(train_this_word)(X, word2den, mask_matrix, this_word)\\\n",
    "                for this_word in wordlist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributing over two cores seems to be worth it. Diminishing returns for more cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could still try to train on keras? https://gist.github.com/fchollet/b7507f373a3446097f26840330c1c378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('at', 1471, 21471, LogisticRegression(max_iter=400, warm_start=True))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wacs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remaining tasks:\n",
    "\n",
    "* evaluation? Run models on training data (with smaller n_neg... maybe balanced? should be option in make_train... which might better be called make_word_dataset...)\n",
    "* how to persist models.. Write out weight matrix and wordlist to disk, as numpy structures? scikit learn objects not very well serialisable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_for_word(X, word2den, mask_matrix, word, neg_max=5):\n",
    "\n",
    "    if word not in word2den:\n",
    "        # raise ValueError(\"No mask available for this word! (%s)\" % (word))\n",
    "        print(\"Error!! No mask available for this word! (%s)\" % (word))\n",
    "        return None\n",
    "    this_mask = mask_matrix[list(word2den.keys()).index(word)]\n",
    "    X_pos = X[this_mask, ID_FEATS:]\n",
    "    y_pos = np.ones(len(X_pos), dtype=int)\n",
    "\n",
    "    # print('made it here!', X_pos.shape)\n",
    "\n",
    "    if neg_max == 0:\n",
    "        return X_pos, y_pos\n",
    "    \n",
    "    if neg_max == 'balanced':\n",
    "        neg_max = len(y_pos)\n",
    "\n",
    "    neg_indx = np.arange(mask_matrix.shape[1])[~this_mask]\n",
    "    np.random.shuffle(neg_indx)\n",
    "    X_neg = X[neg_indx[:neg_max], ID_FEATS:]\n",
    "    y_neg = np.zeros(len(X_neg), dtype=int)\n",
    "\n",
    "    X_out = np.concatenate([X_pos, X_neg], axis=0)\n",
    "    y_out = np.concatenate([y_pos, y_neg])\n",
    "    return shuffle(X_out, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_this_word(X, word2den, mask_matrix, classf_params, this_word):\n",
    "    X_this_w, y_this_w = get_X_for_word(X, word2den, mask_matrix, this_word)\n",
    "    print(this_word, X_this_w.shape[0])\n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        SGDClassifier(**classf_params))\n",
    "    clf.fit(X_this_w, y_this_w)\n",
    "    return (this_word, y_this_w.sum(), len(X_this_w), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classf_params = {'penalty': 'l1', 'warm_start': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 99527 but corresponding boolean dimension is 89545",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/WAC/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/WAC/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/WAC/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/WAC/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/WAC/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;31m# We capture the KeyboardInterrupt and reraise it as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/WAC/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/WAC/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-53ed7f97d58e>\u001b[0m in \u001b[0;36mtrain_this_word\u001b[0;34m(X, word2den, mask_matrix, classf_params, this_word)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_this_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2den\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassf_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_this_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_this_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_X_for_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2den\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_this_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     clf = make_pipeline(StandardScaler(),\n",
      "\u001b[0;32m<ipython-input-36-536c32170943>\u001b[0m in \u001b[0;36mget_X_for_word\u001b[0;34m(X, word2den, mask_matrix, word, neg_max)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mthis_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2den\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mID_FEATS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0my_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 99527 but corresponding boolean dimension is 89545"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wacs = Parallel(n_jobs=2, require='sharedmem', prefer='threads')\\\n",
    "               (delayed(train_this_word)(X, word2den, mask_matrix, classf_params, this_word)\\\n",
    "                for this_word in wordlist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_word, npos, _, this_clsf in wacs:\n",
    "    X_tst, y_tst = get_X_for_word(X_t, word2den, mask_matrix, this_word)\n",
    "    print(this_word, npos, '\\t', \n",
    "          this_clsf.score(X_tst, y_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 1471 \t 0.5720598232494901\n",
      "very 1127 \t 0.6548358473824313\n",
      "top 6202 \t 0.766446307642696\n",
      "guy 2804 \t 0.7378744650499287\n",
      "in 9546 \t 0.6580243033731406\n",
      "the 17007 \t 0.6033104015993415\n",
      "middle 4676 \t 0.6408254918733961\n",
      "front 2992 \t 0.6415441176470589\n",
      "upper 1086 \t 0.7343462246777164\n",
      "right 16454 \t 0.8317430412057858\n"
     ]
    }
   ],
   "source": [
    "for this_word, npos, _, this_clsf in wacs:\n",
    "    X_tst, y_tst = get_X_for_word(X_t, word2den, mask_matrix, this_word)\n",
    "    print(this_word, npos, '\\t', \n",
    "          this_clsf.score(X_tst, y_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on training data (!) unsuprisingly pretty good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_all_test = rc_splits['testA'] + rc_splits['testB']\n",
    "X_ts = filter_X_by_filelist(X, rc_all_test)\n",
    "refdf_test = filter_refdf_by_filelist(refcoco_refdf, rc_all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2den_ts = create_word2den(refdf_test)\n",
    "X_idx_ts = make_X_id_index(X_ts)\n",
    "mask_matrix_ts = make_mask_matrix(X_ts, X_idx_ts, word2den_ts, word2den_ts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow 896 \t0.6483516483516484\n",
      "wooden 53 \t0.6\n",
      "hanging 59 \t0.5\n",
      "second 1922 \t0.6525\n",
      "kids 56 \t0.5\n",
      "glass 533 \t0.7073170731707317\n",
      "hot 186 \t0.65\n",
      "wine 184 \t0.71875\n",
      "backpack 100 \t0.5833333333333334\n",
      "silver 123 \t0.5\n"
     ]
    }
   ],
   "source": [
    "for this_word, npos, _, this_clsf in wacs:\n",
    "    print this_word, npos, '\\t',\n",
    "    X_tst, y_tst = get_X_for_word(X_ts, word2den_ts, mask_matrix_ts, this_word, neg_max='balanced')\n",
    "    print this_clsf.score(X_tst, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow 896 \t0.6813186813186813\n",
      "wooden 53 \t0.6\n",
      "hanging 59 \t0.5\n",
      "second 1922 \t0.5925\n",
      "kids 56 \t0.55\n",
      "glass 533 \t0.7195121951219512\n",
      "hot 186 \t0.675\n",
      "wine 184 \t0.75\n",
      "backpack 100 \t0.5833333333333334\n",
      "silver 123 \t0.5\n"
     ]
    }
   ],
   "source": [
    "for this_word, npos, _, this_clsf in wacs:\n",
    "    print this_word, npos, '\\t',\n",
    "    X_tst, y_tst = get_X_for_word(X_ts, word2den_ts, mask_matrix_ts, this_word, neg_max='balanced')\n",
    "    print this_clsf.score(X_tst, y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's looking not at all so great on the test set... (Although this is not the evaluation that is of ultimate interest here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- persisting the trained model... As weight matrix? (Together with wordlist & other interesting data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_wac = wacs[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.53120489])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_wac.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2056)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([np.append(this_wac.coef_, this_wac.intercept_) \\\n",
    "          for this_wac in [w[3] for w in wacs]]).shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'yellow', 896, 20896),)\n",
      "((u'wooden', 53, 20053),)\n",
      "((u'hanging', 59, 20059),)\n",
      "((u'second', 1922, 21922),)\n",
      "((u'kids', 56, 20056),)\n",
      "((u'glass', 533, 20533),)\n",
      "((u'hot', 186, 20186),)\n",
      "((u'wine', 184, 20184),)\n",
      "((u'backpack', 100, 20100),)\n",
      "((u'silver', 123, 20123),)\n"
     ]
    }
   ],
   "source": [
    "for this_wac in zip([e[:-1] for e in wacs]):\n",
    "    print this_wac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = [e[:-1] for e in wacs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = {\n",
    "        'rcorp': 'refcoco',        # ref corpus\n",
    "        'cnn': 'rsn50-flatten_1',  # CNN used for vision feats\n",
    "        'rel':   'excl',           # exclude relational expressions\n",
    "        'wrdl':  'min',            # wordlist: minimal n occurrences...\n",
    "        'wprm':  40,               # ... 40 times\n",
    "        'clsf':  'logreg-l1',      # logistic regression, l1 regularized\n",
    "        'nneg':  20000,            # maximally 20k neg instances\n",
    "        'nsrc':  'randmax',        # ... randomly selected\n",
    "        'notes': ''\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"nneg\": 20000, \"rcorp\": \"refcoco\", \"clsf\": \"logreg-l1\", \"rel\": \"excl\", \"cnn\": \"rsn50-flatten_1\", \"notes\": \"\", \"wrdl\": \"min\", \"nsrc\": \"randmax\", \"wprm\": 40}, [[\"yellow\", 896, 20896], [\"wooden\", 53, 20053], [\"hanging\", 59, 20059], [\"second\", 1922, 21922], [\"kids\", 56, 20056], [\"glass\", 533, 20533], [\"hot\", 186, 20186], [\"wine\", 184, 20184], [\"backpack\", 100, 20100], [\"silver\", 123, 20123]]]'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps((model, wl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightmatrix_ld = np.load('../ModelsOut/mod01_refcoco.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightmatrix = weightmatrix_ld['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2056)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightmatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196118, 2058)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
